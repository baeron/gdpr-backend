# Azure Pipelines CI/CD for NestJS Backend
# GDPR Audit Backend API

parameters:
  - name: runProdOnly
    type: boolean
    default: false
  - name: enableRedis
    type: boolean
    default: false
    displayName: 'Enable Redis/BullMQ queue (requires more RAM)'

trigger:
  branches:
    include:
      - main
  paths:
    exclude:
      - '*.md'
      - '.github/**'

pr:
  branches:
    include:
      - main

variables:
  nodeVersion: '20.x'
  npmCacheFolder: $(Pipeline.Workspace)/.npm
  # Queue configuration based on parameter
  ${{ if eq(parameters.enableRedis, true) }}:
    queueType: 'redis'
    dockerProfile: 'redis'
  ${{ else }}:
    queueType: 'postgres'
    dockerProfile: 'postgres'

stages:
  # ============================================
  # Stage 1: Build & Test
  # ============================================
  - stage: Build
    displayName: 'Build & Test'
    jobs:
      # # Lint job
      # - job: Lint
      #   displayName: 'Lint'
      #   pool:
      #     vmImage: 'ubuntu-latest'
      #   steps:
      #     - task: NodeTool@0
      #       displayName: 'Install Node.js'
      #       inputs:
      #         versionSpec: $(nodeVersion)

      #     - task: Cache@2
      #       displayName: 'Cache npm packages'
      #       inputs:
      #         key: 'npm | "$(Agent.OS)" | package-lock.json'
      #         restoreKeys: |
      #           npm | "$(Agent.OS)"
      #         path: $(npmCacheFolder)

      #     - script: |
      #         npm ci --cache $(npmCacheFolder)
      #         chmod -R +x node_modules/.bin
      #       displayName: 'Install dependencies'

      #     - script: npx prisma generate
      #       displayName: 'Generate Prisma client'

      #     # - script: npm run lint
      #     #   displayName: 'Run ESLint'

      # # Format check job
      # - job: Format
      #   displayName: 'Format Check'
      #   pool:
      #     vmImage: 'ubuntu-latest'
      #   steps:
      #     - task: NodeTool@0
      #       displayName: 'Install Node.js'
      #       inputs:
      #         versionSpec: $(nodeVersion)

      #     - task: Cache@2
      #       displayName: 'Cache npm packages'
      #       inputs:
      #         key: 'npm | "$(Agent.OS)" | package-lock.json'
      #         restoreKeys: |
      #           npm | "$(Agent.OS)"
      #         path: $(npmCacheFolder)

      #     - script: |
      #         npm ci --cache $(npmCacheFolder)
      #         chmod -R +x node_modules/.bin
      #       displayName: 'Install dependencies'

      #     - script: npx prisma generate
      #       displayName: 'Generate Prisma client'

      #     # - script: npx prettier --check "src/**/*.ts" "test/**/*.ts"
      #     #   displayName: 'Check code formatting'

      # Unit Tests job
      - job: Test
        displayName: 'Unit Tests'
        pool:
          vmImage: 'ubuntu-latest'
        steps:
          - task: NodeTool@0
            displayName: 'Install Node.js'
            inputs:
              versionSpec: $(nodeVersion)

          - task: Cache@2
            displayName: 'Cache npm packages'
            inputs:
              key: 'npm | "$(Agent.OS)" | package-lock.json'
              restoreKeys: |
                npm | "$(Agent.OS)"
              path: $(npmCacheFolder)

          - script: |
              npm ci --cache $(npmCacheFolder)
              chmod -R +x node_modules/.bin
            displayName: 'Install dependencies'

          - script: npx prisma generate
            displayName: 'Generate Prisma client'

          - script: npm run test:cov
            displayName: 'Run unit tests with coverage'

          - task: PublishCodeCoverageResults@2
            displayName: 'Publish code coverage'
            inputs:
              summaryFileLocation: '$(System.DefaultWorkingDirectory)/coverage/cobertura-coverage.xml'
            condition: succeededOrFailed()

          - task: PublishTestResults@2
            displayName: 'Publish test results'
            inputs:
              testResultsFormat: 'JUnit'
              testResultsFiles: '**/junit.xml'
              failTaskOnFailedTests: true
            condition: succeededOrFailed()

      # Build job
      - job: BuildApp
        displayName: 'Build Application'
        dependsOn:
          # - Lint
          # - Format
          - Test
        condition: succeededOrFailed()
        pool:
          vmImage: 'ubuntu-latest'
        steps:
          - task: NodeTool@0
            displayName: 'Install Node.js'
            inputs:
              versionSpec: $(nodeVersion)

          - task: Cache@2
            displayName: 'Cache npm packages'
            inputs:
              key: 'npm | "$(Agent.OS)" | package-lock.json'
              restoreKeys: |
                npm | "$(Agent.OS)"
              path: $(npmCacheFolder)

          - script: |
              npm ci --cache $(npmCacheFolder)
              chmod -R +x node_modules/.bin
            displayName: 'Install dependencies'

          - script: npx prisma generate
            displayName: 'Generate Prisma client'

          - script: npm run build
            displayName: 'Build application'

          - publish: $(System.DefaultWorkingDirectory)/dist
            artifact: dist
            displayName: 'Publish build artifact'

      # E2E Tests job
      - job: E2E
        displayName: 'E2E Tests'
        dependsOn: BuildApp
        pool:
          vmImage: 'ubuntu-latest'
        steps:
          - task: NodeTool@0
            displayName: 'Install Node.js'
            inputs:
              versionSpec: $(nodeVersion)

          - task: Cache@2
            displayName: 'Cache npm packages'
            inputs:
              key: 'npm | "$(Agent.OS)" | package-lock.json'
              restoreKeys: |
                npm | "$(Agent.OS)"
              path: $(npmCacheFolder)

          - script: |
              npm ci --cache $(npmCacheFolder)
              chmod -R +x node_modules/.bin
            displayName: 'Install dependencies'

          - script: npx prisma generate
            displayName: 'Generate Prisma client'

          - download: current
            artifact: dist
            displayName: 'Download build artifact'

          - script: mv $(Pipeline.Workspace)/dist $(System.DefaultWorkingDirectory)/dist
            displayName: 'Restore dist artifact'

          - script: npm run test:e2e
            displayName: 'Run E2E tests'

  # ============================================
  # Stage 2: Deploy to DEV (automatic after Build)
  # ============================================
  - stage: DeployDev
    displayName: 'Deploy to DEV'
    dependsOn: Build
    condition: and(succeeded(), eq(variables['Build.SourceBranch'], 'refs/heads/main'))
    variables:
      - group: vultr-deployment
      - group: gdpr-secrets-dev
    jobs:
      - deployment: DeployDev
        displayName: 'Deploy to DEV Environment'
        pool:
          vmImage: 'ubuntu-latest'
        environment: 'development'
        strategy:
          runOnce:
            deploy:
              steps:
                - checkout: self

                - script: |
                    mkdir -p ~/.ssh
                    echo "$(VULTR_SSH_KEY)" | base64 -d > ~/.ssh/deploy_key
                    chmod 600 ~/.ssh/deploy_key
                    ssh-keyscan -H $(VULTR_HOST) >> ~/.ssh/known_hosts
                  displayName: 'Setup SSH Key'

                - script: |
                    rsync -avz --delete \
                      --exclude 'node_modules' \
                      --exclude '.git' \
                      --exclude 'coverage' \
                      --exclude '.env*' \
                      -e "ssh -i ~/.ssh/deploy_key -o StrictHostKeyChecking=no" \
                      ./ deploy@$(VULTR_HOST):/opt/gdpr-backend/
                  displayName: 'Copy files to server'

                - script: |
                    QUEUE_TYPE="$(queueType)"
                    DOCKER_PROFILE="$(dockerProfile)"
                    
                    ssh -i ~/.ssh/deploy_key -o StrictHostKeyChecking=no deploy@$(VULTR_HOST) << DEPLOY_SCRIPT
                      set -e
                      cd /opt/gdpr-backend
                      
                      echo "=== Starting DEV deployment ==="
                      echo "Queue type: ${QUEUE_TYPE}"
                      echo "Docker profile: ${DOCKER_PROFILE:-none}"
                      
                      # Create DEV env file from Azure DevOps secrets
                      printf '%s\n' \
                        "POSTGRES_USER=$(POSTGRES_USER)" \
                        "POSTGRES_PASSWORD=$(POSTGRES_PASSWORD)" \
                        "POSTGRES_DB=$(POSTGRES_DB)" \
                        "RESEND_API_KEY=$(RESEND_API_KEY)" \
                        "STRIPE_SECRET_KEY=$(STRIPE_SECRET_KEY)" \
                        "STRIPE_WEBHOOK_SECRET=$(STRIPE_WEBHOOK_SECRET)" \
                        "NODE_ENV=development" \
                        "QUEUE_TYPE=${QUEUE_TYPE}" \
                        > .env.devprod

                      # Ensure postgres is running for dev API
                      docker-compose --env-file .env.production up -d postgres
                      docker network inspect gdpr-backend_default >/dev/null 2>&1 || docker network create gdpr-backend_default
                      docker network connect gdpr-backend_default gdpr-postgres >/dev/null 2>&1 || true
                      for i in {1..30}; do
                        status=\$(docker inspect -f '{{.State.Health.Status}}' gdpr-postgres 2>/dev/null || true)
                        if [ "\$status" = "healthy" ]; then
                          echo "Postgres is healthy."
                          break
                        fi
                        echo "Waiting for postgres... (\$i/30)"
                        sleep 2
                      done
                      if [ "\$(docker inspect -f '{{.State.Health.Status}}' gdpr-postgres 2>/dev/null || true)" != "healthy" ]; then
                        echo "Postgres is not healthy."
                        exit 1
                      fi
                      
                      # Stop dev containers (api-dev doesn't have profiles, just stop it)
                      docker-compose --env-file .env.devprod -f docker-compose.devprod.yml stop api-dev || true
                      docker-compose --env-file .env.devprod -f docker-compose.devprod.yml rm -f api-dev || true
                      docker-compose --env-file .env.devprod -f docker-compose.devprod.yml --profile redis stop redis-dev || true
                      docker-compose --env-file .env.devprod -f docker-compose.devprod.yml --profile redis rm -f redis-dev || true
                      
                      # Build and start with selected profile (redis profile adds redis-dev container)
                      echo "Starting DEV with profile: ${DOCKER_PROFILE}"
                      if [ "${DOCKER_PROFILE}" = "redis" ]; then
                        docker-compose --env-file .env.devprod -f docker-compose.devprod.yml --profile redis build --no-cache --pull
                        docker-compose --env-file .env.devprod -f docker-compose.devprod.yml --profile redis up -d
                      else
                        docker-compose --env-file .env.devprod -f docker-compose.devprod.yml build --no-cache --pull
                        docker-compose --env-file .env.devprod -f docker-compose.devprod.yml up -d
                      fi
                      
                      # Wait for container health
                      for i in {1..60}; do
                        status=\$(docker inspect -f '{{.State.Health.Status}}' gdpr-api-dev 2>/dev/null || true)
                        if [ "\$status" = "healthy" ]; then
                          echo "Dev API container is healthy."
                          break
                        fi
                        echo "Waiting for dev API... (\$i/60)"
                        sleep 2
                      done

                      if [ "\$(docker inspect -f '{{.State.Health.Status}}' gdpr-api-dev 2>/dev/null || true)" != "healthy" ]; then
                        echo "Dev API did not become healthy."
                        docker logs --tail=200 gdpr-api-dev || true
                        exit 1
                      fi

                      curl -f http://localhost:3001/api/health
                      echo "=== DEV Deployment successful! ==="
                    DEPLOY_SCRIPT
                  displayName: 'Deploy to DEV'

  # ============================================
  # Stage 3: Deploy to PROD (manual approval required)
  # ============================================
  - stage: DeployProd
    displayName: 'Deploy to PROD'
    dependsOn: DeployDev
    condition: >
      or(
        eq(${{ parameters.runProdOnly }}, true),
        and(succeeded(), eq(variables['Build.SourceBranch'], 'refs/heads/main'))
      )
    variables:
      - group: vultr-deployment
      - group: gdpr-secrets-prod
    jobs:
      - deployment: DeployProduction
        displayName: 'Deploy to PROD Environment'
        pool:
          vmImage: 'ubuntu-latest'
        environment: 'production'  # Requires manual approval in Azure DevOps
        strategy:
          runOnce:
            deploy:
              steps:
                - checkout: self

                - script: |
                    mkdir -p ~/.ssh
                    echo "$(VULTR_SSH_KEY)" | base64 -d > ~/.ssh/deploy_key
                    chmod 600 ~/.ssh/deploy_key
                    ssh-keyscan -H $(VULTR_HOST) >> ~/.ssh/known_hosts
                  displayName: 'Setup SSH Key'

                - script: |
                    rsync -avz --delete \
                      --exclude 'node_modules' \
                      --exclude '.git' \
                      --exclude 'coverage' \
                      --exclude '.env*' \
                      -e "ssh -i ~/.ssh/deploy_key -o StrictHostKeyChecking=no" \
                      ./ deploy@$(VULTR_HOST):/opt/gdpr-backend/
                  displayName: 'Copy files to server'

                - script: |
                    QUEUE_TYPE="$(queueType)"
                    DOCKER_PROFILE="$(dockerProfile)"
                    
                    ssh -i ~/.ssh/deploy_key -o StrictHostKeyChecking=no deploy@$(VULTR_HOST) << DEPLOY_SCRIPT
                      set -e
                      cd /opt/gdpr-backend
                      
                      echo "=== Starting PROD deployment ==="
                      echo "Queue type: ${QUEUE_TYPE}"
                      echo "Docker profile: ${DOCKER_PROFILE:-none}"
                      
                      # Create PROD env file from Azure DevOps secrets
                      printf '%s\n' \
                        "POSTGRES_USER=$(POSTGRES_USER)" \
                        "POSTGRES_PASSWORD=$(POSTGRES_PASSWORD)" \
                        "POSTGRES_DB=$(POSTGRES_DB)" \
                        "RESEND_API_KEY=$(RESEND_API_KEY)" \
                        "STRIPE_SECRET_KEY=$(STRIPE_SECRET_KEY)" \
                        "STRIPE_WEBHOOK_SECRET=$(STRIPE_WEBHOOK_SECRET)" \
                        "NODE_ENV=production" \
                        "QUEUE_TYPE=${QUEUE_TYPE}" \
                        > .env.production
                      
                      # Stop API containers (both postgres and redis variants)
                      docker-compose --env-file .env.production --profile postgres stop api || true
                      docker-compose --env-file .env.production --profile postgres rm -f api || true
                      docker-compose --env-file .env.production --profile redis stop api-redis || true
                      docker-compose --env-file .env.production --profile redis rm -f api-redis || true
                      
                      # Build and start with selected profile
                      echo "Starting with profile: ${DOCKER_PROFILE}"
                      docker-compose --env-file .env.production --profile ${DOCKER_PROFILE} build --no-cache --pull
                      docker-compose --env-file .env.production --profile ${DOCKER_PROFILE} up -d
                      
                      # Wait for health check
                      for i in {1..30}; do
                        if curl -sf http://localhost:3000/api/health > /dev/null 2>&1; then
                          echo "Health check passed!"
                          break
                        fi
                        echo "Waiting... (\$i/30)"
                        sleep 2
                      done
                      
                      curl -f http://localhost:3000/api/health || exit 1
                      
                      docker-compose ps
                      echo "=== PROD Deployment successful! ==="
                    DEPLOY_SCRIPT
                  displayName: 'Deploy to PROD'

                - script: |
                    ssh -i ~/.ssh/deploy_key -o StrictHostKeyChecking=no deploy@$(VULTR_HOST) << 'EOF'
                      docker image prune -f
                    EOF
                  displayName: 'Cleanup old images'
                  condition: succeeded()

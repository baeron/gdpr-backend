# Azure Pipelines CI/CD for NestJS Backend
# GDPR Audit Backend API

trigger:
  branches:
    include:
      - main
  paths:
    exclude:
      - '*.md'
      - '.github/**'

pr:
  branches:
    include:
      - main

variables:
  nodeVersion: '20.x'
  npmCacheFolder: $(Pipeline.Workspace)/.npm
  # Queue configuration: 'postgres' (default, no Redis) or 'redis' (requires more RAM)
  queueType: 'postgres'
  # Docker Compose profile: '' (default), 'redis', or 'scaled'
  dockerProfile: ''

stages:
  # ============================================
  # Stage 1: Build & Test
  # ============================================
  - stage: Build
    displayName: 'Build & Test'
    jobs:
      # # Lint job
      # - job: Lint
      #   displayName: 'Lint'
      #   pool:
      #     vmImage: 'ubuntu-latest'
      #   steps:
      #     - task: NodeTool@0
      #       displayName: 'Install Node.js'
      #       inputs:
      #         versionSpec: $(nodeVersion)

      #     - task: Cache@2
      #       displayName: 'Cache npm packages'
      #       inputs:
      #         key: 'npm | "$(Agent.OS)" | package-lock.json'
      #         restoreKeys: |
      #           npm | "$(Agent.OS)"
      #         path: $(npmCacheFolder)

      #     - script: |
      #         npm ci --cache $(npmCacheFolder)
      #         chmod -R +x node_modules/.bin
      #       displayName: 'Install dependencies'

      #     - script: npx prisma generate
      #       displayName: 'Generate Prisma client'

      #     # - script: npm run lint
      #     #   displayName: 'Run ESLint'

      # # Format check job
      # - job: Format
      #   displayName: 'Format Check'
      #   pool:
      #     vmImage: 'ubuntu-latest'
      #   steps:
      #     - task: NodeTool@0
      #       displayName: 'Install Node.js'
      #       inputs:
      #         versionSpec: $(nodeVersion)

      #     - task: Cache@2
      #       displayName: 'Cache npm packages'
      #       inputs:
      #         key: 'npm | "$(Agent.OS)" | package-lock.json'
      #         restoreKeys: |
      #           npm | "$(Agent.OS)"
      #         path: $(npmCacheFolder)

      #     - script: |
      #         npm ci --cache $(npmCacheFolder)
      #         chmod -R +x node_modules/.bin
      #       displayName: 'Install dependencies'

      #     - script: npx prisma generate
      #       displayName: 'Generate Prisma client'

      #     # - script: npx prettier --check "src/**/*.ts" "test/**/*.ts"
      #     #   displayName: 'Check code formatting'

      # Unit Tests job
      - job: Test
        displayName: 'Unit Tests'
        pool:
          vmImage: 'ubuntu-latest'
        steps:
          - task: NodeTool@0
            displayName: 'Install Node.js'
            inputs:
              versionSpec: $(nodeVersion)

          - task: Cache@2
            displayName: 'Cache npm packages'
            inputs:
              key: 'npm | "$(Agent.OS)" | package-lock.json'
              restoreKeys: |
                npm | "$(Agent.OS)"
              path: $(npmCacheFolder)

          - script: |
              npm ci --cache $(npmCacheFolder)
              chmod -R +x node_modules/.bin
            displayName: 'Install dependencies'

          - script: npx prisma generate
            displayName: 'Generate Prisma client'

          - script: npm run test:cov
            displayName: 'Run unit tests with coverage'

          - task: PublishCodeCoverageResults@2
            displayName: 'Publish code coverage'
            inputs:
              summaryFileLocation: '$(System.DefaultWorkingDirectory)/coverage/cobertura-coverage.xml'
            condition: succeededOrFailed()

          - task: PublishTestResults@2
            displayName: 'Publish test results'
            inputs:
              testResultsFormat: 'JUnit'
              testResultsFiles: '**/junit.xml'
              failTaskOnFailedTests: true
            condition: succeededOrFailed()

      # Build job
      - job: BuildApp
        displayName: 'Build Application'
        dependsOn:
          # - Lint
          # - Format
          - Test
        condition: succeededOrFailed()
        pool:
          vmImage: 'ubuntu-latest'
        steps:
          - task: NodeTool@0
            displayName: 'Install Node.js'
            inputs:
              versionSpec: $(nodeVersion)

          - task: Cache@2
            displayName: 'Cache npm packages'
            inputs:
              key: 'npm | "$(Agent.OS)" | package-lock.json'
              restoreKeys: |
                npm | "$(Agent.OS)"
              path: $(npmCacheFolder)

          - script: |
              npm ci --cache $(npmCacheFolder)
              chmod -R +x node_modules/.bin
            displayName: 'Install dependencies'

          - script: npx prisma generate
            displayName: 'Generate Prisma client'

          - script: npm run build
            displayName: 'Build application'

          - publish: $(System.DefaultWorkingDirectory)/dist
            artifact: dist
            displayName: 'Publish build artifact'

      # E2E Tests job
      - job: E2E
        displayName: 'E2E Tests'
        dependsOn: BuildApp
        pool:
          vmImage: 'ubuntu-latest'
        steps:
          - task: NodeTool@0
            displayName: 'Install Node.js'
            inputs:
              versionSpec: $(nodeVersion)

          - task: Cache@2
            displayName: 'Cache npm packages'
            inputs:
              key: 'npm | "$(Agent.OS)" | package-lock.json'
              restoreKeys: |
                npm | "$(Agent.OS)"
              path: $(npmCacheFolder)

          - script: |
              npm ci --cache $(npmCacheFolder)
              chmod -R +x node_modules/.bin
            displayName: 'Install dependencies'

          - script: npx prisma generate
            displayName: 'Generate Prisma client'

          - download: current
            artifact: dist
            displayName: 'Download build artifact'

          - script: mv $(Pipeline.Workspace)/dist $(System.DefaultWorkingDirectory)/dist
            displayName: 'Restore dist artifact'

          - script: npm run test:e2e
            displayName: 'Run E2E tests'

  # ============================================
  # Stage 2: Deploy to DEV (automatic after Build)
  # ============================================
  - stage: DeployDev
    displayName: 'Deploy to DEV'
    dependsOn: Build
    condition: and(succeeded(), eq(variables['Build.SourceBranch'], 'refs/heads/main'))
    variables:
      - group: vultr-deployment
      - group: gdpr-secrets-dev
    jobs:
      - deployment: DeployDev
        displayName: 'Deploy to DEV Environment'
        pool:
          vmImage: 'ubuntu-latest'
        environment: 'development'
        strategy:
          runOnce:
            deploy:
              steps:
                - checkout: self

                - script: |
                    mkdir -p ~/.ssh
                    echo "$(VULTR_SSH_KEY)" | base64 -d > ~/.ssh/deploy_key
                    chmod 600 ~/.ssh/deploy_key
                    ssh-keyscan -H $(VULTR_HOST) >> ~/.ssh/known_hosts
                  displayName: 'Setup SSH Key'

                - script: |
                    rsync -avz --delete \
                      --exclude 'node_modules' \
                      --exclude '.git' \
                      --exclude 'coverage' \
                      --exclude '.env*' \
                      -e "ssh -i ~/.ssh/deploy_key -o StrictHostKeyChecking=no" \
                      ./ deploy@$(VULTR_HOST):/opt/gdpr-backend/
                  displayName: 'Copy files to server'

                - script: |
                    ssh -i ~/.ssh/deploy_key -o StrictHostKeyChecking=no deploy@$(VULTR_HOST) << 'DEPLOY_SCRIPT'
                      set -e
                      cd /opt/gdpr-backend
                      
                      echo "=== Starting DEV deployment ==="
                      
                      # Create DEV env file from Azure DevOps secrets
                      cat > .env.devprod << ENV_FILE
                    POSTGRES_USER=$(POSTGRES_USER)
                    POSTGRES_PASSWORD=$(POSTGRES_PASSWORD)
                    POSTGRES_DB=$(POSTGRES_DB)
                    RESEND_API_KEY=$(RESEND_API_KEY)
                    STRIPE_SECRET_KEY=$(STRIPE_SECRET_KEY)
                    STRIPE_WEBHOOK_SECRET=$(STRIPE_WEBHOOK_SECRET)
                    NODE_ENV=development
                    ENV_FILE

                      # Ensure postgres is running for dev API
                      docker-compose --env-file .env.production up -d postgres
                      for i in {1..30}; do
                        status=$(docker inspect -f '{{.State.Health.Status}}' gdpr-postgres 2>/dev/null || true)
                        if [ "$status" = "healthy" ]; then
                          echo "Postgres is healthy."
                          break
                        fi
                        echo "Waiting for postgres... ($i/30)"
                        sleep 2
                      done
                      if [ "$(docker inspect -f '{{.State.Health.Status}}' gdpr-postgres 2>/dev/null || true)" != "healthy" ]; then
                        echo "Postgres is not healthy."
                        exit 1
                      fi
                      
                      docker-compose --env-file .env.devprod -f docker-compose.devprod.yml down --remove-orphans || true
                      docker-compose --env-file .env.devprod -f docker-compose.devprod.yml build --no-cache --pull
                      docker-compose --env-file .env.devprod -f docker-compose.devprod.yml up -d
                      
                      # Wait for health check
                      for i in {1..30}; do
                        if curl -sf http://localhost:3001/api/health > /dev/null 2>&1; then
                          echo "Health check passed!"
                          break
                        fi
                        echo "Waiting... ($i/30)"
                        sleep 2
                      done
                      
                      curl -f http://localhost:3001/api/health || exit 1
                      echo "=== DEV Deployment successful! ==="
                    DEPLOY_SCRIPT
                  displayName: 'Deploy to DEV'

  # ============================================
  # Stage 3: Deploy to PROD (manual approval required)
  # ============================================
  - stage: DeployProd
    displayName: 'Deploy to PROD'
    dependsOn: DeployDev
    condition: and(succeeded(), eq(variables['Build.SourceBranch'], 'refs/heads/main'))
    variables:
      - group: vultr-deployment
      - group: gdpr-secrets-prod
    jobs:
      - deployment: DeployProduction
        displayName: 'Deploy to PROD Environment'
        pool:
          vmImage: 'ubuntu-latest'
        environment: 'production'  # Requires manual approval in Azure DevOps
        strategy:
          runOnce:
            deploy:
              steps:
                - checkout: self

                - script: |
                    mkdir -p ~/.ssh
                    echo "$(VULTR_SSH_KEY)" | base64 -d > ~/.ssh/deploy_key
                    chmod 600 ~/.ssh/deploy_key
                    ssh-keyscan -H $(VULTR_HOST) >> ~/.ssh/known_hosts
                  displayName: 'Setup SSH Key'

                - script: |
                    rsync -avz --delete \
                      --exclude 'node_modules' \
                      --exclude '.git' \
                      --exclude 'coverage' \
                      --exclude '.env*' \
                      -e "ssh -i ~/.ssh/deploy_key -o StrictHostKeyChecking=no" \
                      ./ deploy@$(VULTR_HOST):/opt/gdpr-backend/
                  displayName: 'Copy files to server'

                - script: |
                    ssh -i ~/.ssh/deploy_key -o StrictHostKeyChecking=no deploy@$(VULTR_HOST) << 'DEPLOY_SCRIPT'
                      set -e
                      cd /opt/gdpr-backend
                      
                      echo "=== Starting PROD deployment ==="
                      
                      # Create PROD env file from Azure DevOps secrets
                      cat > .env.production << ENV_FILE
                    POSTGRES_USER=$(POSTGRES_USER)
                    POSTGRES_PASSWORD=$(POSTGRES_PASSWORD)
                    POSTGRES_DB=$(POSTGRES_DB)
                    RESEND_API_KEY=$(RESEND_API_KEY)
                    STRIPE_SECRET_KEY=$(STRIPE_SECRET_KEY)
                    STRIPE_WEBHOOK_SECRET=$(STRIPE_WEBHOOK_SECRET)
                    NODE_ENV=production
                    ENV_FILE
                      
                      docker-compose --env-file .env.production down --remove-orphans || true
                      docker-compose --env-file .env.production build --no-cache --pull
                      docker-compose --env-file .env.production up -d
                      
                      # Wait for health check
                      for i in {1..30}; do
                        if curl -sf http://localhost:3000/api/health > /dev/null 2>&1; then
                          echo "Health check passed!"
                          break
                        fi
                        echo "Waiting... ($i/30)"
                        sleep 2
                      done
                      
                      curl -f http://localhost:3000/api/health || exit 1
                      
                      docker-compose ps
                      echo "=== PROD Deployment successful! ==="
                    DEPLOY_SCRIPT
                  displayName: 'Deploy to PROD'

                - script: |
                    ssh -i ~/.ssh/deploy_key -o StrictHostKeyChecking=no deploy@$(VULTR_HOST) << 'EOF'
                      docker image prune -f
                    EOF
                  displayName: 'Cleanup old images'
                  condition: succeeded()
